{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "sun: tf.sequence_mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cab99e3e405c2c80"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:40.260689Z",
     "start_time": "2024-06-30T16:09:37.991945100Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://blog.csdn.net/xinjieyuan/article/details/95760679 : 对sequence_mask进行讲解"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "882e87250da1b8fc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False]\n",
      " [ True  True  True  True False]], shape=(2, 5), dtype=bool)\n",
      "tf.Tensor([[ True  True False False False]], shape=(1, 5), dtype=bool)\n",
      "tf.Tensor([[ True False False False False]], shape=(1, 5), dtype=bool)\n",
      "tf.Tensor([ True False False False False], shape=(5,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# 例子举得是，第一个参数length是代表nlp中每个句子的长度，然后生成的是，对每个句子的掩码\n",
    "# 第一个参数为列表：列表中每一个数字代表序列的长度\n",
    "# 第一个参数为数字，代表一个序列的长度\n",
    "print(tf.sequence_mask([3, 4], 5)) # 一个列表，有2个序列 mask：2 * 5 (2个序列，每个序列5个掩码)\n",
    "print(tf.sequence_mask([2], 5))  #  一个列表，有1个序列 mask：1 * 5\n",
    "print(tf.sequence_mask([1], 5))\n",
    "print(tf.sequence_mask(1, 5)) # 就一个序列，mask ： 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:09:40.303713400Z",
     "start_time": "2024-06-30T16:09:40.261693Z"
    }
   },
   "id": "b26df7e5d842d90d",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sequence_mask对tensor操作的理解\n",
    "input本身是一个特征数为1的输入层，样本就是 [x], 多个样本就类似于 [1], [2], [4] ...., 掩码后类似于，[[...(20位)]] 多个样本的掩码 [[...(20位)]], [[...(20位)]], ..... 所以input的形状是：none * 1，最后掩码的形状是 none * 1 * 20 ，每个样本，一个特征，这个特征20维度的掩码\n",
    "\n",
    "input 如果我们创建keras(2,)这代表这个输入层有两个特征，样本就是 [x, y], 多个样本就类似于 [1, 2], [3, 4], [5, 6]...., 掩码后类似于 [[...(20位)], [...(20位)]]\n",
    "所以input的形状：none * 2, 最后掩码的形状是：none * 2 * 20, 每个样本，2个特征，每个特征都有20维度的掩码"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3135cceab9c96821"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 1), dtype=int64, sparse=None, name=input>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 掩码长度维20的时候，生成的掩码张量形状为：[1, 20]\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m input_sequence \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequence_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxlen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(input_sequence)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 这是一个形状为[2, 4]的张量\u001B[39;00m\n",
      "File \u001B[1;32mE:\\project\\muti-scene-rec\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mE:\\project\\muti-scene-rec\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:91\u001B[0m, in \u001B[0;36mKerasTensor.__tf_tensor__\u001B[1;34m(self, dtype, name)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__tf_tensor__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     92\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     93\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mused when constructing Keras Functional models \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     95\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     97\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand `keras.operations`). \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     98\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are likely doing something like:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    100\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx = Input(...)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m...\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf_fn(x)  # Invalid.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    103\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    104\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    105\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    106\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass MyLayer(Layer):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def call(self, x):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    108\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return tf_fn(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx = MyLayer()(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    111\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# 这是一个张量，维度是1, 代表了一个序列的长度\n",
    "input = keras.Input(shape=(1,), name='input', dtype=tf.int64)\n",
    "print(input)\n",
    "# 掩码长度维20的时候，生成的掩码张量形状为：[1, 20]\n",
    "input_sequence = tf.sequence_mask(input, maxlen=20, dtype=tf.float32)\n",
    "print(input_sequence)\n",
    "\n",
    "# 这是一个形状为[2, 4]的张量\n",
    "input = keras.Input(shape=(2,), name='input', dtype=tf.int64)\n",
    "input_sequence = tf.sequence_mask(input, maxlen=20, dtype=tf.float32)\n",
    "print(input_sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T16:23:43.403249100Z",
     "start_time": "2024-06-30T16:23:43.351086400Z"
    }
   },
   "id": "e62a46f8a5538694",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "10daad7c4d5433f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
